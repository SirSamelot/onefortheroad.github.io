{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Hello!  In this tutorial we will scrape a more complicated page from Wikipedia.  This is a continuation of [Part 1]({% post_url 2017-04-29-web-scraping-part-1 %}) where we learned the basics of web scraping.\n",
    "\n",
    "When we left off Part 1, we had a *pandas* dataframe containing the Top 100 Canadian Beers. I'd like to add some **geospatial** information to our beer list so I can plan a pilgrimage to these fantastic breweries.  (Actually, we'll use this geospatial information in a future tutorial on visualization.)  Wikipedia's [List of Breweries in Canada](https://en.wikipedia.org/wiki/List_of_breweries_in_Canada) is a fine place to start.  Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Import Libraries](#1-import-libraries)\n",
    "2. [Download the web page](#2-download-the-web-page)\n",
    "3. [Examine the HTML](#3-examine-the-html)\n",
    "4. [Parse the HTML](#4-parse-the-html)\n",
    "5. [Extract Data](#5-extract-data)\n",
    "6. [Putting it all together](#6-putting-it-all-together)\n",
    "7. [Create pandas dataframe](#7-create-pandas-dataframe)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_breweries_in_Canada'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Examine the HTML\n",
    "Looking at the [wiki](https://en.wikipedia.org/wiki/List_of_breweries_in_Canada), the breweries are listed by province.  The HTML for the breweries in Alberta looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<h3><span class=\"mw-headline\" id=\"Alberta\">Alberta</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=List_of_breweries_in_Canada&amp;action=edit&amp;section=2\" title=\"Edit section: Alberta\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
    "<ul>\n",
    "<li>Alley Kat Brewing Company (<a href=\"/wiki/Edmonton\" title=\"Edmonton\">Edmonton</a>)</li>\n",
    "...\n",
    "</ul>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start thinking of the structure, and hence our parse logic, as follows:\n",
    "- Heading `<h3>` followed by a `<span>` with class `mw-headline` gives the province\n",
    "- Each province is followed by an unordered list `<ul>` of breweries\n",
    "- Each list item `<li>` represents an individual brewery\n",
    "- Repeat for each province"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Parse the HTML\n",
    "We'll first turn our `page` object into a Beautiful Soup object, then start looking for the headings denoting provinces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Alberta\n",
      "2 British Columbia\n",
      "3 Manitoba\n",
      "4 Newfoundland & Labrador\n",
      "5 Northwest Territories\n",
      "6 Nova Scotia\n",
      "7 New Brunswick\n",
      "8 Ontario\n",
      "9 Prince Edward Island\n",
      "10 Saskatchewan\n",
      "11 Quebec\n",
      "12 Yukon\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "provinces = soup.find_all(lambda tag: tag.name == 'h3' and tag.find(class_='mw-headline'))\n",
    "# Print the list of provinces\n",
    "for i, province in enumerate(provinces, start=1):\n",
    "    print(i, province.contents[0].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We use a lambda function in `find_all()` because we want to find only tags with particular children, and Beautiful Soup doesn't have any methods to do this directly.  Our lambda function does this quite elegantly in a single line.\n",
    "\n",
    ">Why didn't we just search for all `<h3>` tags, or `mw_headline` classes?  These searches would have turned up other elements as well, leading to additional steps to get only the ones we want.  Try it out as an exercise!\n",
    "{:.blockquote}\n",
    "\n",
    "Next, using the first province in the list (Alberta), let's get the list of breweries which are in the `<li>` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Alley Kat Brewing Company (Edmonton)\n",
      "2 Amber's Brewing Company (Edmonton)\n",
      "3 Banded Peak Brewing Company (Calgary)\n",
      "4 Banff Ave. Brewing Co. (Banff)\n",
      "5 Bent Stick Brewing Co. (Edmonton)\n"
     ]
    }
   ],
   "source": [
    "brewers_by_province = provinces[0].find_next_sibling('ul').find_all('li')\n",
    "# Truncate the printed list to first 5 brewers\n",
    "for i, brewery in enumerate(brewers_by_province[:5], start=1):\n",
    "    print(i, brewery.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain this line.  Working with the first province `provinces[0]`, we went sideways in the tree using `find_next_sibling()` to the unordered list `<ul>`.  Inside the `<ul>` we then gathered all the `<li>` tags using `find_all()`.\n",
    "\n",
    "# 5. Extract Data\n",
    "The data we want is the brewery's name and city. Scanning through the list of brewers, we see that the text can be in any of the following formats.\n",
    "- Alley Kat Brewing Company (Edmonton)\n",
    "- Brewsters Brewing Company (Calgary), (Edmonton)\n",
    "- Andina Brewing Co. (Vancouver - Opening in 2017)\n",
    "- Agassiz Brewing (Winnipeg, defunct)\n",
    "- 1827–1962: The Bennett Brewing Company (St. John's)\n",
    "- 1997–present: Garrison Brewing Company\\[2\\](Halifax)\n",
    "- 2013–present: Boxing Rock Brewing Company [3] (Shelburne)\n",
    "- 1786–present: Molson\n",
    "- Albion (Since 2011) (Joliette)\n",
    "- La Voie Maltée (Since 2002) (Jonquière, Chicoutimi, Québec)\n",
    "\n",
    "Thank you Wikipedia for your consistency.\n",
    "\n",
    "In order to make sure our extraction code will handle all these different formats, we'll first create a list, `sample`, containing both simple and complex examples.  Then we'll test our extraction code on `sample` to make sure it handles all the variations.\n",
    "\n",
    "### a. Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley Kat Brewing Company (Edmonton)\n",
      "Brewsters Brewing Company (Calgary), (Edmonton)\n",
      "1997–present: Garrison Brewing Company[2](Halifax)\n",
      "1786–present: Molson\n",
      "Albion (Since 2011) (Joliette)\n",
      "La Voie Maltée (Since 2002) (Jonquière, Chicoutimi, Québec)\n"
     ]
    }
   ],
   "source": [
    "alley_kat = 'Alley Kat Brewing Company (Edmonton)'\n",
    "brewsters = 'Brewsters Brewing Company (Calgary), (Edmonton)'\n",
    "garrison = '1997–present: Garrison Brewing Company[2](Halifax)'\n",
    "molson = '1786–present: Molson'\n",
    "albion = 'Albion (Since 2011) (Joliette)'\n",
    "la_voie_maltee = 'La Voie Maltée (Since 2002) (Jonquière, Chicoutimi, Québec)'\n",
    "sample = [alley_kat, brewsters, garrison, molson, albion, la_voie_maltee]\n",
    "for brewer in sample:\n",
    "    print(brewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Remove unnecessary text\n",
    "If there is any text before the brewery's name, let's get rid of it.  It looks like the colon character is used to separate the text we want to keep and the text to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley Kat Brewing Company (Edmonton)\n",
      "Brewsters Brewing Company (Calgary), (Edmonton)\n",
      "Garrison Brewing Company[2](Halifax)\n",
      "Molson\n",
      "Albion (Since 2011) (Joliette)\n",
      "La Voie Maltée (Since 2002) (Jonquière, Chicoutimi, Québec)\n"
     ]
    }
   ],
   "source": [
    "for brewer in sample:\n",
    "    data = brewer.split(':', maxsplit=1)[-1].strip()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Extract brewery name\n",
    "Next we'll get the name of the brewer, which is all the text before either a square bracket `[` or a parenthesis `(`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley Kat Brewing Company \n",
      "Brewsters Brewing Company \n",
      "Garrison Brewing Company\n",
      "Molson\n",
      "Albion \n",
      "La Voie Maltée \n"
     ]
    }
   ],
   "source": [
    "pattern_text_before_brackets = r'[^[\\(]+'  # pattern to match all text before [ or ( character\n",
    "for brewer in sample:\n",
    "    data = brewer.split(':', maxsplit=1)[-1].strip()\n",
    "    name = re.match(pattern_text_before_brackets, data).group()\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Extract city name\n",
    "Finally, let's get all the text inside the parentheses.  *Usually* there is only one parentheses group, and *usually* it contains a city.  However, there are exceptions:\n",
    "- multiple groups, like *(Calgary), (Edmonton)*\n",
    "- no parenthesis at all, like the entry for *Molson*\n",
    "- non-city text like *Since 2002*\n",
    "- multiple cities inside one group, like *Jonquière, Chicoutimi, Québec*\n",
    "\n",
    "This might get ugly, but we'll break it down into parts.  **First step** is to get any and all text within parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edmonton']\n",
      "['Calgary', 'Edmonton']\n",
      "['Halifax']\n",
      "[]\n",
      "['Since 2011', 'Joliette']\n",
      "['Since 2002', 'Jonquière, Chicoutimi, Québec']\n"
     ]
    }
   ],
   "source": [
    "pattern_text_in_brackets = r'\\((.*?)\\)'  # pattern to match all text within (...)\n",
    "for brewer in sample:\n",
    "    # Get a list of all text within parentheses\n",
    "    cities = re.findall(pattern_text_in_brackets, brewer)\n",
    "    print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a start, but the results are all over the place.  We need to **clean** this text and make it consistent by converting the text into a list of city names.  We will build on our previous code and do the following:\n",
    "- split comma-separated lists into individual cities\n",
    "- remove any text that aren't cities e.g. *Since 2002*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edmonton']\n",
      "['Calgary', 'Edmonton']\n",
      "['Halifax']\n",
      "[]\n",
      "['Joliette']\n",
      "['Jonquière', 'Chicoutimi', 'Québec']\n"
     ]
    }
   ],
   "source": [
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten a list of lists without flattening strings\"\"\"\n",
    "    for x in list_of_lists:\n",
    "        if hasattr(x, '__iter__') and not isinstance(x, str):\n",
    "            for y in flatten(x):\n",
    "                yield y\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "pattern_text_in_brackets = r'\\((.*?)\\)' # pattern to match all text within (...)\n",
    "pattern_no_digits = r'^[^\\d]*$'  # pattern to match text that doesn't contain any digits\n",
    "\n",
    "for brewer in sample:\n",
    "    # Get a list of all text within parentheses\n",
    "    cities = re.findall(pattern_text_in_brackets, brewer)\n",
    "    \n",
    "    # split any strings containing comma seperated city names\n",
    "    cities = [item.split(', ') if ',' in item else item for item in cities]\n",
    "    \n",
    "    # flatten the resulting list of of cities\n",
    "    cities = list(flatten(cities))\n",
    "    \n",
    "    # remove any \"cities\" with numbers\n",
    "    cities = [item for item in cities if re.match(pattern_no_digits, item)]\n",
    "        \n",
    "    print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot happened there.  After getting a list of all the text within parentheses, we then **split any text** that was a list of comma separated cities.  Notice the delimiter `', '` was used to remove the single space after the comma when splitting.  We could have used just a comma, but then we would be left with whitespace that would require additional calls to `.strip()`.  Again, a tradeoff between robustness and readability.  Also notice that the split is conditional and only occurs if there is a comma in the text group.  We don't want to split cities like *Mont-Tremblant* with a hyphen in their name.\n",
    "\n",
    "The result of a `split()` is a list, which would leave us with a nested list.  We don't want that, so a helper function `flatten()` is written that will **flatten nested lists** while leaving strings untouched.\n",
    "\n",
    "Finally, I am quite confident that no cities have a number in their name, so we **eliminate text groups with digits**.  This removes the text groups like *Since 2002*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Putting it all together \n",
    "Ready to apply all of the above to our entire set of data?  Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brewery_data = []  # initialize an empty list to contain the breweries\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten a list of lists without flattening strings\"\"\"\n",
    "    for x in list_of_lists:\n",
    "        if hasattr(x, '__iter__') and not isinstance(x, str):\n",
    "            for y in flatten(x):\n",
    "                yield y\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "for province in provinces:\n",
    "    # Get the name of the province\n",
    "    province_name = province.contents[0].string.strip()\n",
    "\n",
    "    # Get a list of breweries\n",
    "    breweries = province.find_next_sibling('ul').find_all('li')\n",
    "    \n",
    "    for brewery in breweries:\n",
    "        # Remove unnecessary text\n",
    "        data = brewery.text.split(':', maxsplit=1)[-1].strip()\n",
    "        \n",
    "        # Extract name of the brewery\n",
    "        pattern_text_before_brackets = r'[^[\\(]+'  # pattern to match all text before [ or ( character\n",
    "        name = re.match(pattern_text_before_brackets, data).group().strip()\n",
    "        \n",
    "        # Extract list of cities\n",
    "        pattern_text_in_brackets = r'\\((.*?)\\)'  # pattern to match all text within (...)\n",
    "        \n",
    "        # Get a list of all text within parentheses\n",
    "        cities = re.findall(pattern_text_in_brackets, brewery.text)\n",
    "        \n",
    "        # split any strings containing comma seperated city names\n",
    "        cities = [item.split(', ') if ',' in item else item for item in cities]\n",
    "        \n",
    "        # flatten the resulting list of of cities\n",
    "        cities = list(flatten(cities))\n",
    "        \n",
    "        # remove any \"cities\" with numbers\n",
    "        pattern_no_digits = r'^[^\\d]*$'  # pattern to match text that doesn't contain any digits\n",
    "        cities = [item for item in cities if re.match(pattern_no_digits, item)]\n",
    "        \n",
    "        # Gather into a single dictionary\n",
    "        brewer = {\n",
    "            'name': name,\n",
    "            'city': cities,\n",
    "            'province': province_name\n",
    "        }\n",
    "        \n",
    "        # Add the brewery to our brewery list\n",
    "        brewery_data.append(brewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create *pandas* dataframe\n",
    "With the dictionary of all the scraped breweries, `brewery_data`, we can now create a *pandas* dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         city                         name province\n",
      "0  [Edmonton]    Alley Kat Brewing Company  Alberta\n",
      "1  [Edmonton]      Amber's Brewing Company  Alberta\n",
      "2   [Calgary]  Banded Peak Brewing Company  Alberta\n",
      "3     [Banff]       Banff Ave. Brewing Co.  Alberta\n",
      "4  [Edmonton]       Bent Stick Brewing Co.  Alberta\n",
      "\n",
      "                                city                    name province\n",
      "501               [Sapporo, Chambly]                Unibroue   Quebec\n",
      "502  [Jonquière, Chicoutimi, Québec]          La Voie Maltée   Quebec\n",
      "503   [Quebec City, Laval, Brossard]        Les 3 Brasseurs,   Quebec\n",
      "504                     [Whitehorse]       Yukon Brewing Co.    Yukon\n",
      "505                     [Whitehorse]  Winterlong Brewing Co.    Yukon\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(brewery_data)\n",
    "print(df.head(), df.tail(), sep='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great!  There's still a lot of data cleaning to do, but we'll save that for the next tutorial.  Let's finish by **saving this dataframe** into a csv file so we can access it again later.  I like to put local copies of files in a subdirectory of my working directory called `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './data/breweries_in_canada_messy.csv'\n",
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! *pandas* has a convenient method `to_csv()` which writes a dataframe into a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Congratulations! After getting this far, you're now ready to wield the might of **Beautiful Soup** and **regex** to scrape web pages for data!  In our next tutorial, we'll focus on using *pandas* to clean our data.  Remember, our current dataframe contains the raw data from the Wikipedia page, but it has some issues:\n",
    "- the `city` feature is a list object, and sometimes the list contains multiple entries (e.g. *Unibroue*)\n",
    "- some entries in `name` end with a comma (e.g. *Les 3 Brasseurs,*) so we should fix that\n",
    "\n",
    "And that's just from looking at the tail of our dataframe!  What other problems will we find?  Stay tuned and thanks for reading!\n",
    "\n",
    ">Have a question about this tutorial, or a suggestion for a future tutorial? Please, leave a comment below!\n",
    "{:.blockquote}\n",
    "\n",
    "### Resources\n",
    "- Beautiful Soup [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [regex101](https://regex101.com/), online regex tester"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
