{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Hello!  In this tutorial, we will learn ways to use *pandas* to clean a dataset.  Our ultimate goal is a tidy dataset. We will cover:\n",
    "\n",
    "- What is tidy data?\n",
    "- Cleaning text data\n",
    "\n",
    "\n",
    "At the end of [Part 2]({% post_url 2017-05-10-web-scraping-part-2 %}) we had a dataframe with a list of all the Canadian brewers on [this](https://en.wikipedia.org/wiki/List_of_breweries_in_Canada) Wikipedia page. However, we already know there are some problems with the dataset, and I'm sure we will uncover a few more as we explore it in more detail.  Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [What is tidy data](#1-what-is-tidy-data)\n",
    "2. [Our (messy) data](#2-our-messy-data)\n",
    "3. [Unpacking a list](#3-unpacking-a-list)\n",
    "4. [Cleaning text strings](#4-cleaning-text-strings)\n",
    "5. [Trivia](#5-trivia)\n",
    "6. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is tidy data?\n",
    "The term **tidy data** was popularized by Hadley Wickham in a 2014 paper, [Tidy Data](https://www.jstatsoft.org/article/view/v059i10).  This paper is essential reading for anyone working in data science. According to Wickham, a tidy dataset is one in which:\n",
    ">  each variable is a column, each observation is a row, and each type of observational unit is a table\n",
    "{:.blockquote}\n",
    "\n",
    "Further, a tidy dataset is easy for computers to manipulate, model, and visualize.  These are all worthy goals that make a data scientist's life easier, so we should always seek to tidy our data.  Let's take a look at our dataset.\n",
    "\n",
    "# 2. Our (messy) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         city                         name province\n",
      "0  [Edmonton]    Alley Kat Brewing Company  Alberta\n",
      "1  [Edmonton]      Amber's Brewing Company  Alberta\n",
      "2   [Calgary]  Banded Peak Brewing Company  Alberta\n",
      "3     [Banff]       Banff Ave. Brewing Co.  Alberta\n",
      "4  [Edmonton]       Bent Stick Brewing Co.  Alberta\n",
      "\n",
      "                                city                    name province\n",
      "501               [Sapporo, Chambly]                Unibroue   Quebec\n",
      "502  [Jonquière, Chicoutimi, Québec]          La Voie Maltée   Quebec\n",
      "503   [Quebec City, Laval, Brossard]        Les 3 Brasseurs,   Quebec\n",
      "504                     [Whitehorse]       Yukon Brewing Co.    Yukon\n",
      "505                     [Whitehorse]  Winterlong Brewing Co.    Yukon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "filename = './data/breweries_in_canada_messy.csv'\n",
    "df = pd.read_csv(filename, index_col=[0], converters={\"city\": literal_eval}, encoding='ISO-8859-1')\n",
    "\n",
    "print(df.head(), df.tail(), sep='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few wrinkles we have to contend with when reading our data file.  They are the result of us calling the `to_csv()` function with no arguments when we originally created the CSV file.\n",
    "\n",
    "- The `index` column was explicitly created as a column in the CSV file.  So to treat it as a proper `index` and not another column of data, we pass in the parameter `index_col=[0]` so *pandas* knows the first column is an index column.\n",
    "- When we wrote the column `city`, we passed in the list object directly.  Once in CSV form, it is no longer a list object but a string.  So to tell *pandas* that the `city` column is actually full of list objects and not strings, we call in a converter that tell is to \"literally evaluate\" the contents.  Thus we get our column of list objects back.\n",
    "- For some reason, the default file encoding used when writing the CSV file can't be used to read the CSV file again.  So we explicitly pass in `encoding='ISO-8859-1'` in order to read the file correctly.\n",
    "\n",
    "The first problem with our data is that the every value in the `city` variable is a list object.  This is a byproduct of how we scraped the data (see [Web Scraping: Part 2]({% post_url 2017-05-10-web-scraping-part-2 %}).  *pandas* has trouble accessing contents of a list, so we wouldn't be able to use its powerful features for analysis.  Also, some list objects have multiple contents, which means this fails the criteria for tidy data. So the first thing we will do is unpack these list objects and create separate rows for multi-city breweries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unpacking a list\n",
    "Let's take a look at one of our problem rows, the brewery by the name of *La Voie Maltée*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                city            name province\n",
      "502  [Jonquière, Chicoutimi, Québec]  La Voie Maltée   Quebec\n"
     ]
    }
   ],
   "source": [
    "print(df[df.name=='La Voie Maltée'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has three cities listed in its `city` variable.  So ideally, we want to create three new rows, one for each city.  I'll admit this took me a while to figure out, but [cwharland](http://stackoverflow.com/users/1968405/cwharland) came up with a lovely one-liner.  Take a look [here](http://stackoverflow.com/questions/28442358/splitting-a-list-inside-a-pandas-dataframe) to see the full explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name province        city\n",
      "257  La Voie Maltée   Quebec   Jonquière\n",
      "258  La Voie Maltée   Quebec  Chicoutimi\n",
      "259  La Voie Maltée   Quebec      Québec\n"
     ]
    }
   ],
   "source": [
    "df = df.groupby(['name', 'province']).city.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_2', axis = 1)\n",
    "df.columns = ['name', 'province', 'city']  # rename the variables after above operation\n",
    "print(df[df.name=='La Voie Maltée'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Much better! \n",
    "\n",
    "# 4. Cleaning text strings\n",
    "Again, just from looking at `.tail()`, I can see that the brewery *Les 3 Brasseurs,* has a comma at the end of their name.  Not all punctuation at the end of a name is bad (for example, *Banff Ave. Brewing Co.* or *Dieu du ciel!*) but commas definitely are.  Just curious, how many breweries have undesirable punctuation at the end of their name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name          province         city\n",
      "54   Big Ridge Brewing Co.]  British Columbia       Surrey\n",
      "115             C'est What?           Ontario      Toronto\n",
      "275        Les 3 Brasseurs,            Quebec  Quebec City\n",
      "276        Les 3 Brasseurs,            Quebec        Laval\n",
      "277        Les 3 Brasseurs,            Quebec     Brossard\n"
     ]
    }
   ],
   "source": [
    "pattern = r'[^\\w!.]$'  # pattern to find end of string isn't a letter, comma, nor exclamation mark\n",
    "print(df[df.name.str.contains(pattern)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5 rows, not as bad as I thought.  We even found an unexpected character, `]`, hiding in there.  And *C'est What?* is actually a legitimate name, so really only 4 entries that need to be fixed.  Let's get rid of those unwanted characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, province, city]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "pattern = r'[^\\w!.?]$'  # pattern to find last character is undesired character\n",
    "df.name = df.name.str.replace(pattern, '')\n",
    "print(df[df.name.str.contains(pattern)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our dataframe for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = './data/breweries_in_canada_clean.csv'\n",
    "df.to_csv(filename, index=False, columns=['name', 'city', 'province'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Trivia\n",
    "Already we can use our data for some simple observations.\n",
    "\n",
    "### Observation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name province     city\n",
      "count              509      509      509\n",
      "unique             496       12      259\n",
      "top     La Voie Maltée  Ontario  Toronto\n",
      "freq                 3      211       46\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 496 breweries in 259 cities.\n",
    "\n",
    "### Observation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontario                    211\n",
      "British Columbia           103\n",
      "Quebec                      90\n",
      "Alberta                     39\n",
      "Newfoundland & Labrador     19\n",
      "Nova Scotia                 15\n",
      "Manitoba                    10\n",
      "Saskatchewan                 8\n",
      "New Brunswick                6\n",
      "Prince Edward Island         5\n",
      "Yukon                        2\n",
      "Northwest Territories        1\n",
      "Name: province, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.province.value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ontario leads the way with more than twice the number of breweries than the next province on the list.\n",
    "\n",
    "### Observation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto       46\n",
      "Vancouver     24\n",
      "Ottawa        22\n",
      "Calgary       15\n",
      "St. John's    11\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.city.value_counts(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 cities with the most breweries are Toronto, Vancouver, Ottawa, Calgary, and St. John's.  (Although this one is misleading as many of the breweries listed under St. John's don't exist anymore.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We now have a dataframe that is much better than before.  However, there are still some problems. For example:\n",
    "- some entries are duplicates (e.g. Labatt & Labatt Brewing)\n",
    "- some entries from the Wikipedia page were removed if their city information was written like so: \"CrossRoads Brewing (Prince George - Opening in 2017)\n",
    "- some entries have incorrect or invalid city information (e.g. *defunct* for Agassiz Brewing)\n",
    "- some of the breweries don't exist anymore\n",
    "\n",
    "You can see some of the inherent fallacies in scraping and cleaning textual data from a web page.  It's an inexact science and requires a lot of work to build a robust scraper, not to mention validating the resulting data.  But even with our imperfect dataset, we picked out some interesting trivia.\n",
    "\n",
    "Note that we didn't cover very common and important topics like dealing with **missing data** and **normalizing data**.  We'll talk about these in a future tutorial when we work with numeric data sets.\n",
    "\n",
    "I do think we have enough information to use with our Top 100 Beer list (from [Web Scraping: Part 1]({% post_url 2017-04-29-web-scraping-part-1 %}) so we'll leave this dataframe as is.  Our next tutorial will show how to **join dataframes**, and later we'll show an example of **data visualization**.  Until then, cheers!\n",
    "\n",
    "> Have a question about this topic, or a suggestion for a future topic?  Please, leave a comment below!\n",
    "{:.blockquote}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
