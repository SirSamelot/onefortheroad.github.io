{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Hello! In Part 1 of this two-part tutorial, we're going to learn how to:\n",
    "- Get a simple web page into Python\n",
    "- Extract data from the web page\n",
    "- Turn that data into a Pandas dataframe\n",
    "\n",
    "Since I love my country, just as much as I love delicious fermented malt beverages, we'll be working with the *Top Rated Beers from Canada*, as ranked by users on [BeerAdvocate](www.beeradvocate.com).\n",
    "\n",
    "Part 2 of this tutorial shows how to scrape a slightly more complex page, and a future tutorial will cover how to merge the data from these two different sources into a single dataframe for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Pre-requisites*\n",
    "- a basic understanding of HTML, CSS, and Python\n",
    "\n",
    ">If any of these are unfamiliar, make sure you check out the [resources](#resources) at the end of this tutorial.\n",
    "{:.blockquote}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libaries\n",
    "First, we need to import some required libraries.  For this tutorial, these libraries will be used for the following:\n",
    "* `re`: extract text from strings using Regular Expressions\n",
    "* `requests`: download html pages\n",
    "* `bs4`: BeautifulSoup extracts text from html pages quickly and elegantly\n",
    "* `pandas`: high-performance data structure and analysis tools\n",
    "\n",
    "I recommend reading their respective documentation to fully learn the amazing capabilities of these libraries.  But not right now.  We're here to learn how to scrape web data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the webpage\n",
    "It is very easy to download a webpage using the requests library.  We just pass in the URL as a string to `requests.get()`.  This will return a `Response` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.beeradvocate.com/lists/ca/'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the `page` object a bit more.  The following will return the HTTP status code of the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code of 200 means all is well.  The familiar 404 would be returned for File Not Found if the URL we requested pointed to a non-existent file.  Other status codes can be returned too.\n",
    "\n",
    "> In a production setting, you should always handle any unexpected status codes.  How would you do that?  *Hint: `requests` will raise exceptions, so it's up to you to catch them!*\n",
    "{:.blockquote}\n",
    "\n",
    "Now let's take a look at the first 500 characters of what we downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\n\\n\\n\\n\\t\\n\\n\\n\\n\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\n\\t\\t\\n\\t\\n\\n\\n<html id=\"XenForo\" lang=\"en-US\" dir=\"LTR\" class=\"Public NoJs uix_javascriptNeedsInit LoggedOut Sidebar  Responsive pageIsLtr   not_hasTabLinks  hasSearch   is-sidebarOpen hasRightSidebar is-setWidth navStyle_3 pageStyle_0 hasFlexbox\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n<head>\\n\\n\\n\\t<meta charset=\"utf-8\" />\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge,chrome=1\" />\\n\\t\\n\\t\\t<meta name=\"viewport\" content=\"width'\n"
     ]
    }
   ],
   "source": [
    "print(page.content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa, OK, hang on a minute.  What's all this?  If I squint hard enough, I can start picking out html tags here and there, and now my eyes are blurry and I'm not even drinking anything.\n",
    "\n",
    "What `page.text` did was return the raw contents of the downloaded html file.  That's a great start (thank you `requests.get()`) but what we want is that table of Top 100 beers.  That brings us to our next tool, **Beautiful Soup**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parsing the html, or \"What devilry is this?!\"\n",
    "Now that we have a nice `page` object containing our page's HTML code, we can then use the magic inside Beautiful Soup to pick out the parts we want.  This is called *parsing*.  To start, we simply instantiate Beautiful Soup with our page's content using the *lxml* HTML parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `soup` object that is ready for us to poke around.  Behind the scenes, Beautiful Soup has turned the HTML into a nested data structure.  The full scope of Beautiful Soup is beyond this tutorial, but let's explore the basics.\n",
    "\n",
    "First, we now have access to a nicely formatted version of our downloaded page.  Here's a snippet of the first 1000 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"Public NoJs uix_javascriptNeedsInit LoggedOut Sidebar Responsive pageIsLtr not_hasTabLinks hasSearch is-sidebarOpen hasRightSidebar is-setWidth navStyle_3 pageStyle_0 hasFlexbox\" dir=\"LTR\" id=\"XenForo\" lang=\"en-US\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=Edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <base href=\"https://www.beeradvocate.com/community/\"/>\n",
      "  <script>\n",
      "   var _b = document.getElementsByTagName('base')[0], _bH = \"https://www.beeradvocate.com/community/\";\n",
      "\t\t\tif (_b && _b.href != _bH) _b.href = _bH;\n",
      "  </script>\n",
      "  <title>\n",
      "   Top Rated Beers: Canada | BeerAdvocate\n",
      "  </title>\n",
      "  <noscript>\n",
      "   <style>\n",
      "    .JsOnly, .jsOnly { display: none !important; }\n",
      "   </style>\n",
      "  </noscript>\n",
      "  <link href=\"css.php?css=xenforo,form,public&amp;style=7&amp;dir=LTR&amp;d=1492562935\" rel=\"stylesheet\"/>\n",
      "  <link href=\"css.php?css=login_bar,mode\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than `page.content` don't you agree?\n",
    "\n",
    "Let's learn the basics of navigating a Beautiful Soup object.\n",
    "\n",
    "One common task is seaching for HTML sections by tag.  For example, let's search for all `<h1>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>Top Rated Beers: Canada</h1>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all()` finds every instance of the tag(s) in its argument list, and returns a list of `Tag` object.  In our case, there was only a single `<h1>` tag.\n",
    "\n",
    "`Tag` objects have a number of attributes and methods.  For example, look at the output of the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Top Rated Beers: Canada</h1>\n",
      "['Top Rated Beers: Canada']\n",
      "Top Rated Beers: Canada\n"
     ]
    }
   ],
   "source": [
    "h1_tags = soup.find_all('h1')  # returns a list\n",
    "print(h1_tags[0])\n",
    "print(h1_tags[0].contents)\n",
    "print(h1_tags[0].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two things.  Since `find_all()` returned a list, we access the first (and in this case, only) list item with the index [0]. Also, notice the difference in outputs depending on how we accessed `h1_tags[0]`.  We'll explore this further later on.\n",
    "\n",
    "What happens when more than one tag is found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 <h3> tags.\n",
      "[<h3>Lists</h3>, <h3>FAQ</h3>, <h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-caret-square-o-right\"></i>\n",
      "\t\t\t\t\t\t\t\tAbout Us\n",
      "\t\t\t\t\t\t\t</h3>, <h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-beer\"></i>\n",
      "\t\t\t\t\t\t\t\tBeerAdvocate Microbrew Invitational\n",
      "\t\t\t\t\t\t\t</h3>, <h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-book\"></i>\n",
      "\t\t\t\t\t\t\t\tSubscribe to BeerAdvocate Magazine\n",
      "\t\t\t\t\t\t\t</h3>]\n"
     ]
    }
   ],
   "source": [
    "h3_tags = soup.find_all('h3')\n",
    "print('There are {} <h3> tags.'.format(len(h3_tags)))\n",
    "print(h3_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since `find_all()` returns a list, we can easily iterate over the list to look at each individual tag.  This is a technique you will use often.  For example, let's print a numbered list of each `<h3>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\t<h3>Lists</h3>\n",
      "1.\t<h3>FAQ</h3>\n",
      "2.\t<h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-caret-square-o-right\"></i>\n",
      "\t\t\t\t\t\t\t\tAbout Us\n",
      "\t\t\t\t\t\t\t</h3>\n",
      "3.\t<h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-beer\"></i>\n",
      "\t\t\t\t\t\t\t\tBeerAdvocate Microbrew Invitational\n",
      "\t\t\t\t\t\t\t</h3>\n",
      "4.\t<h3 class=\"bigFooterHeader\">\n",
      "<i class=\"uix_icon fa fa-book\"></i>\n",
      "\t\t\t\t\t\t\t\tSubscribe to BeerAdvocate Magazine\n",
      "\t\t\t\t\t\t\t</h3>\n"
     ]
    }
   ],
   "source": [
    "for index, tag in enumerate(h3_tags):\n",
    "    print('{}.\\t{}'.format(index, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, look how far we've come!  We went from a mash of HTML tags (the soup) and we've extracted an ordered list of specific tags.\n",
    "\n",
    "There are many ways to search through Beautiful Soup objects.  There are also many ways to navigate the structure of the soup which mirror the HTML structure of the document.  We will explore this further in Part II of this tutorial, and I encourage you to look at Beautiful Soup's excellent [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "For now, we know enough to be dangerous, and we can start parsing this relatively simple page.\n",
    "\n",
    "## 4. Examine the HTML structure\n",
    "In order to parse our HTML Page, *Top Rated Canadian Beers*, we have to understand what we are looking for.  Since we're interested in the table of beers, right click the table header and select \"Inspect\" to enter your browser's HTML code inspector.  A snippet of the HTML table looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<table width=\"100%\" cellpadding=\"2\" cellspacing=\"0\" border=\"0\">\n",
    "<tr>\n",
    "<td colspan=\"4\" width=\"100%\" align=\"left\" valign=\"top\" bgcolor=\"#000000\"><span style=\"color: #FFFFFF; font-weight: bold;\">Top Rated Beers: Canada</span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td width=\"5%\" align=\"left\" valign=\"middle\" bgcolor=\"#F0F0F0\">&nbsp;</td>\n",
    "\t<td width=\"60%\" align=\"left\" valign=\"middle\" bgcolor=\"#F0F0F0\">&nbsp;</td>\n",
    "\t<td width=\"10%\" align=\"left\" valign=\"middle\" bgcolor=\"#F0F0F0\">WR</td>\n",
    "\t<td width=\"25%\" align=\"right\" valign=\"middle\" bgcolor=\"#F0F0F0\">Reviews | Ratings</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td align=\"center\" valign=\"top\" class=\"hr_bottom_light\" bgcolor=\"#F7F7F7\">\n",
    "\t\t<span style=\"font-weight:bold;color:#666666;\">1</span></td>\n",
    "\t<td align=\"left\" valign=\"middle\" class=\"hr_bottom_light\">\n",
    "\t\t<a href=\"/beer/profile/1141/10325/\"><b>Péché Mortel</b></a>\n",
    "\t\t<div id=\"extendedInfo\"><a href=\"/beer/profile/1141/\">Brasserie Dieu du Ciel!</a><br>\n",
    "\t\t<a href=\"/beer/style/157/\">American Double / Imperial Stout</a> / 9.50% ABV</div></td>\n",
    "\t<td align=\"left\" valign=\"top\" class=\"hr_bottom_light\"><b>4.39</span></td><td align=\"right\" valign=\"top\" class=\"hr_bottom_light\"><b>1,828</b> <span class=\"muted\">| 5,081</span></td>\n",
    "</tr>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our table is contained within the `<table>` tag. A quick `find_all()` will let us know if there are other `<table>` tags in our document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(soup.find_all('table')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news, there is only one `<table>` in our document.  If there were others, we would have to take care to find the one we're interested in (this technique will be covered in Part II).\n",
    "\n",
    "We further notice that each beer is contained in its own `<tr>` tag, and each beer's details are contained within `<td>` tags.  (For a quick primer on HTML tables, take a look [here](https://developer.mozilla.org/en/docs/Web/HTML/Element/table).)\n",
    "\n",
    "Armed with this knowledge, let's grab each `<tr>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "rows = soup.find_all('tr')\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute... looking in our browser, we see that there are 100 beers in the list.  Why are there 102 rows in our table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td align=\"center\" bgcolor=\"#F7F7F7\" class=\"hr_bottom_light\" valign=\"top\"><span style=\"font-weight:bold;color:#666666;\">1</span></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"middle\"><a href=\"/beer/profile/1141/10325/\"><b>Péché Mortel</b></a><div id=\"extendedInfo\"><a href=\"/beer/profile/1141/\">Brasserie Dieu du Ciel!</a><br/><a href=\"/beer/style/157/\">American Double / Imperial Stout</a> / 9.50% ABV</div></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"top\"><b>4.39</b></td>, <td align=\"right\" class=\"hr_bottom_light\" valign=\"top\"><b>5,086</b></td>] \n",
      "\n",
      "[<td align=\"center\" bgcolor=\"#F7F7F7\" class=\"hr_bottom_light\" valign=\"top\"><span style=\"font-weight:bold;color:#666666;\">2</span></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"middle\"><a href=\"/beer/profile/1141/50803/\"><b>Péché Mortel En Fût De Bourbon Américain</b></a><div id=\"extendedInfo\"><a href=\"/beer/profile/1141/\">Brasserie Dieu du Ciel!</a><br/><a href=\"/beer/style/157/\">American Double / Imperial Stout</a> / 9.50% ABV</div></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"top\"><b>4.45</b></td>, <td align=\"right\" class=\"hr_bottom_light\" valign=\"top\"><b>488</b></td>] \n",
      "\n",
      "[<td align=\"center\" bgcolor=\"#F7F7F7\" class=\"hr_bottom_light\" valign=\"top\"><span style=\"font-weight:bold;color:#666666;\">3</span></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"middle\"><a href=\"/beer/profile/22/34/\"><b>La Fin Du Monde</b></a><div id=\"extendedInfo\"><a href=\"/beer/profile/22/\">Unibroue</a><br/><a href=\"/beer/style/58/\">Tripel</a> / 9.00% ABV</div></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"top\"><b>4.31</b></td>, <td align=\"right\" class=\"hr_bottom_light\" valign=\"top\"><b>10,020</b></td>] \n",
      "\n",
      "[<td align=\"center\" bgcolor=\"#F7F7F7\" class=\"hr_bottom_light\" valign=\"top\"><span style=\"font-weight:bold;color:#666666;\">4</span></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"middle\"><a href=\"/beer/profile/22/76874/\"><b>Unibroue 17 Grande Réserve</b></a><div id=\"extendedInfo\"><a href=\"/beer/profile/22/\">Unibroue</a><br/><a href=\"/beer/style/56/\">Belgian Strong Dark Ale</a> / 10.00% ABV</div></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"top\"><b>4.24</b></td>, <td align=\"right\" class=\"hr_bottom_light\" valign=\"top\"><b>1,140</b></td>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rows[0].contents, '\\n')\n",
    "print(rows[1].contents, '\\n')\n",
    "print(rows[2].contents, '\\n')\n",
    "print(rows[3].contents, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah-ha!  The first two `<tr>` are table headers, and our beer list actually starts at index 2.  We can rewrite our `find_all()` as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[<td align=\"center\" bgcolor=\"#F7F7F7\" class=\"hr_bottom_light\" valign=\"top\"><span style=\"font-weight:bold;color:#666666;\">1</span></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"middle\"><a href=\"/beer/profile/1141/10325/\"><b>Péché Mortel</b></a><div id=\"extendedInfo\"><a href=\"/beer/profile/1141/\">Brasserie Dieu du Ciel!</a><br/><a href=\"/beer/style/157/\">American Double / Imperial Stout</a> / 9.50% ABV</div></td>, <td align=\"left\" class=\"hr_bottom_light\" valign=\"top\"><b>4.39</b></td>, <td align=\"right\" class=\"hr_bottom_light\" valign=\"top\"><b>5,086</b></td>]\n"
     ]
    }
   ],
   "source": [
    "rows = soup.find_all('tr')[2:]\n",
    "print(len(rows))\n",
    "print(rows[0].contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!  `rows` is now a list of 100 table rows, each containing a single beer entry.  We now have to go down to the next level in the HTML structure and get the `<td>` tags which correspond to each column in the row.  We'll start with the first row, and later we will put this all in a loop to process every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.\t[<span style=\"font-weight:bold;color:#666666;\">1</span>]\n",
      "1.\t[<a href=\"/beer/profile/1141/10325/\"><b>Péché Mortel</b></a>, <div id=\"extendedInfo\"><a href=\"/beer/profile/1141/\">Brasserie Dieu du Ciel!</a><br/><a href=\"/beer/style/157/\">American Double / Imperial Stout</a> / 9.50% ABV</div>]\n",
      "2.\t[<b>4.39</b>]\n",
      "3.\t[<b>5,086</b>]\n"
     ]
    }
   ],
   "source": [
    "col = rows[0].find_all('td')\n",
    "print(len(col))\n",
    "for index, column in enumerate(col):\n",
    "    print('{}.\\t{}'.format(index, column.contents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work!  We found all four columns of data, and now we can better see the contents of each column.  \n",
    "\n",
    "## 5. Extract data\n",
    "Let's work through each column one at a time and extract the information into easily understood variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "rank = int(col[0].string.strip())\n",
    "print(rank, type(rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the first column's value in a variable named `rank`.   Here we introduce a few new things:\n",
    "- `.string` gets only the string contents of a `Tag`.  Since we don't care about the other tags (e.g. the `<span>` tag), this is exactly what we need\n",
    "- `.strip()` is a Python function that strips leading and trailing whitespace from a string.  It's usually a good idea to use this when parsing HTML strings, just in case there are any hidden whitespace characters in the text.  \n",
    "- explicitly cast to type `int` so Python knows it is a number and not a string\n",
    "\n",
    "Let's do the same thing on the next column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-51362d3378d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcol1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "col1 = col[1].string.strip()\n",
    "print(col1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh!  What happened?  Looking back at the second column, we can see that it contains a lot more than just a single value within a single tag.  In fact, it contains four values: the beer's name, the brewery, the style, and the ABV, all contained within their own tags.  What's happening is `col[1]` contains multiple *children*, with each child having their own string.   When this happens to `.string`, it's not clear which string it should return, so it returns a `None` object.  Then when `strip()` is called on a `None` object, it throws the error above.\n",
    "\n",
    "So how do we fix this?  Just like before, we go down another level in the HTML structure!  To be clear, there are multiple ways to do this next step, so use the below as an example and  practice other methods on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Péché Mortel | Brasserie Dieu du Ciel! | American Double / Imperial Stout\n"
     ]
    }
   ],
   "source": [
    "col1_a_tag = col[1].find_all('a')\n",
    "beer_name = col1_a_tag[0].string.strip()\n",
    "brewery = col1_a_tag[1].string.strip()\n",
    "style = col1_a_tag[2].string.strip()\n",
    "print(beer_name, brewery, style, sep=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good.  We astutely noticed that three of the four values in the second column are located inside their own `<a>` tag, so we grabbed them like we did before.  However, the last value, the ABV, isn't like the others.  It's not contained within its own tag at all.  Never fear, Beautiful Soup to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ 9.50% ABV\n"
     ]
    }
   ],
   "source": [
    "abv = col1_a_tag[2].next_sibling.strip()\n",
    "print(abv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet!  What did we do exactly?  Since the ABV is right after the beer style, we used Beautiful Soup's `.next_sibling` attribute on the beer style tag, and boom we've got what we wanted!  Well, not exactly.  There's the `/` character in front that's a bit ugly.  Also, for future data analysis we will probably want to treat the ABV as a number and not a string.  So let's get the ABV as a number only, and for that we use Python's powerful Regular Expression library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "abv = float(re.findall(r\"(?<![a-zA-Z:])[-+]?\\d*\\.?\\d+\", abv)[0])\n",
    "print(abv, type(abv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long expression within `re.findall()` is known a *Regular Expression*, or *regex* for short.  Basically, this particular *regex* finds and returns a numeric value contained within a string.  There are many ways to write this expression, and I would recommend becoming familiar with *regex* if you plan to do any sort of text or expression matching work.  Google has a great overview on *regex* [here](https://developers.google.com/edu/python/regular-expressions).\n",
    "\n",
    "Whew, that second column was a bit of work.  Armed with our new skills, we can make short work of the  next two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39 <class 'float'>\n",
      "5086 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "score = float(col[2].string.strip())\n",
    "ratings = int(col[3].string.strip().replace(',', ''))\n",
    "print(score, type(score))\n",
    "print(ratings, type(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we removed the thousands separator in `ratings` before casting it into an `int`.\n",
    "\n",
    "Now let's put it all together by neatly packaging all that information into a single dictionary  we'll call `beer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beer = {\n",
    "    'rank': rank,\n",
    "    'name': beer_name,\n",
    "    'brewery': brewery,\n",
    "    'style': style,\n",
    "    'abv': abv,\n",
    "    'score': score,\n",
    "    'ratings': ratings\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for a little review.  We've read in a single table row containing a beer, and extracted seven different values from that row.  We've cleaned up these values a bit so that they are ready for future analysis.  Finally, we stored all these values as key-value pairs in a dictionary.  Now, we just have to do this all again for the the next 99 beers.  Say what?  Well, that's where Python comes in.\n",
    "\n",
    "## 6. Extract *all* the data\n",
    "Putting everything in Section 5 into a loop, we can very quickly extract the data from the entire table.  The resulting loop could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beers = []  # Initialize an empty list to contain all the beer\n",
    "for row in soup.find_all('tr')[2:]: \n",
    "    col = row.find_all('td')\n",
    "    \n",
    "    # First column\n",
    "    rank = int(col[0].string.strip())\n",
    "    \n",
    "    # Second column\n",
    "    col1_a_tag = col[1].find_all('a')\n",
    "    beer_name = col1_a_tag[0].string.strip()\n",
    "    brewery = col1_a_tag[1].string.strip()\n",
    "    style = col1_a_tag[2].string.strip()\n",
    "    abv = col1_a_tag[2].next_sibling.strip()\n",
    "    abv = float(re.findall(r\"(?<![a-zA-Z:])[-+]?\\d*\\.?\\d+\", abv)[0])\n",
    "    \n",
    "    # Third column\n",
    "    score = float(col[2].string.strip())\n",
    "    \n",
    "    # Fourth column\n",
    "    ratings = int(col[3].string.strip().replace(',', ''))\n",
    "    \n",
    "    # Gather into a single dictionary\n",
    "    beer = {\n",
    "        'rank': rank,\n",
    "        'name': beer_name,\n",
    "        'brewery': brewery,\n",
    "        'style': style,\n",
    "        'abv': abv,\n",
    "        'score': score,\n",
    "        'ratings': ratings\n",
    "    }\n",
    "    \n",
    "    # Add the beer to our beer list\n",
    "    beers.append(beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list, `beers`, containing the data we extracted from the entire table.  For example, let's look at the first and last beers in the `beers` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rank': 1, 'name': 'Péché Mortel', 'brewery': 'Brasserie Dieu du Ciel!', 'style': 'American Double / Imperial Stout', 'abv': 9.5, 'score': 4.39, 'ratings': 5086} \n",
      " {'rank': 100, 'name': 'Rigor Mortis Abt', 'brewery': 'Brasserie Dieu du Ciel!', 'style': 'Quadrupel (Quad)', 'abv': 10.5, 'score': 3.91, 'ratings': 759}\n"
     ]
    }
   ],
   "source": [
    "print(beers[0], '\\n', beers[99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is good, but we want to be great. You can see that accessing this dictionary is a bit ungainly, and that would make any sort of processing or analysis clumsy and painful.  Enter *pandas* stage left! \n",
    "\n",
    "## 7. We heart pandas, and not only the fuzzy endangered variety\n",
    "*pandas* is a library for data analysis in Python.  (Check out the [resources](#resources) section at the end for more information).  We're barely going to skim the surface of *pandas* in ths tutorial, but rest assured we will use it much more in future tutorials.\n",
    "\n",
    "Let's convert our `beers` dictionary into a *pandas* dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abv                  brewery                                      name  rank  ratings  score                             style\n",
      "0   9.5  Brasserie Dieu du Ciel!                              Péché Mortel     1     5086   4.39  American Double / Imperial Stout\n",
      "1   9.5  Brasserie Dieu du Ciel!  Péché Mortel En Fût De Bourbon Américain     2      488   4.45  American Double / Imperial Stout\n",
      "2   9.0                 Unibroue                           La Fin Du Monde     3    10020   4.31                            Tripel\n",
      "3  10.0                 Unibroue                Unibroue 17 Grande Réserve     4     1140   4.24           Belgian Strong Dark Ale\n",
      "4   7.0        Driftwood Brewery                               Fat Tug IPA     5      601   4.25                      American IPA\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(beers)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice!  In one line we turned our list of dictionaries `beers` into a dataframe named `df`.  One of the really cool features of DataFrames is access to the `.head()` method.  This method displays the first 5 lines of the dataframe.  There is a similar method `.tail()` that prints out the last 5 lines of the dataframe.  You can also pass an integer *n* as an argument to these methods and it will display *n* lines instead of the default 5.\n",
    "\n",
    "Notice the following:\n",
    "- the columns are arranged alphabetically\n",
    "- *pandas* inserted a column without a heading, numbered 0 to 99, at the very left.  This is known as the *index*\n",
    "\n",
    "Let's modify our dataframe a bit to make it a bit more user-friendly.  We are going to\n",
    "- arrange the columns in a more logical manner\n",
    "- use the `rank` column as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          name                  brewery                             style   abv  score  ratings\n",
      "rank                                                                                                                           \n",
      "1                                 Péché Mortel  Brasserie Dieu du Ciel!  American Double / Imperial Stout   9.5   4.39     5086\n",
      "2     Péché Mortel En Fût De Bourbon Américain  Brasserie Dieu du Ciel!  American Double / Imperial Stout   9.5   4.45      488\n",
      "3                              La Fin Du Monde                 Unibroue                            Tripel   9.0   4.31    10020\n",
      "4                   Unibroue 17 Grande Réserve                 Unibroue           Belgian Strong Dark Ale  10.0   4.24     1140\n",
      "5                                  Fat Tug IPA        Driftwood Brewery                      American IPA   7.0   4.25      601\n"
     ]
    }
   ],
   "source": [
    "# Index using the beer's rank\n",
    "df = df.set_index('rank')\n",
    "\n",
    "# Reorder the columns\n",
    "columnTitles = ['name', 'brewery', 'style', 'abv', 'score', 'ratings']\n",
    "df = df.reindex(columns=columnTitles)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!\n",
    "\n",
    "One last thing to quickly demonstrate one of the reasons we use *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              abv       score       ratings\n",
      "count  100.000000  100.000000    100.000000\n",
      "mean     8.272000    4.143100    513.520000\n",
      "std      1.931613    0.110597   1311.998033\n",
      "min      4.400000    3.910000     50.000000\n",
      "25%      6.575000    4.067500     91.500000\n",
      "50%      8.550000    4.140000    135.000000\n",
      "75%     10.000000    4.202500    271.000000\n",
      "max     12.200000    4.480000  10020.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pandas* can quickly summarize key statistics for numeric values.  Cool!\n",
    "\n",
    "## Conclusion\n",
    "One basic truth of web scraping is that it is inherently unreliable.  Web content changes, quickly and often, and your code will soon break.  Case in point: in the time it took to create this tutorial, BeerAdvocate removed one column of their Top 100 tables, thus requiring a rewrite of my draft code.  Don't ever get discouraged; consider it a challenge to develop robust and flexible web scrapers.\n",
    "\n",
    "In **Web Scraping: Part 1**, we took a simple table from a webpage and converted its contents into a tabular form that is ready for analysis.  Tools like Beautiful Soup and *pandas* did most of the heavy lifting.  Our simple code has much room for improvement.  In Web Scraping: Part 2, we will scrape a (slightly) more complicated web page.  For now, all this work has made me quite thirsty...\n",
    "\n",
    "*Leave a comment!  Let me know what you thought of this tutorial, and what you would like to see in future tutorials.  Thanks for reading!*\n",
    "\n",
    "### Resources\n",
    "- Intro to HTML & CSS by [codecademy](https://www.codecademy.com/learn/learn-html-css)\n",
    "- Intro to Python by [codecademy](https://www.codecademy.com/learn/python)\n",
    "- Beautiful Soup [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- Google's Regular Expressions [tutorial](https://developers.google.com/edu/python/regular-expressions)\n",
    "- [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
